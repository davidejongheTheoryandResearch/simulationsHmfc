{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d0d8d6-5eae-437f-9898-1da65482a064",
   "metadata": {},
   "source": [
    "## Fitting hMFC to an empirical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e681b33a-cd37-454c-a44c-fe32aad91831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jax.nn import sigmoid\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from fastprogress import progress_bar\n",
    "import numpy as np\n",
    "import dill\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "from hmfc.model import HierarchicalBernoulliLDS\n",
    "from hmfc.gibbs import gibbs_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc6a59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\", context=\"paper\",\n",
    "        font=\"Arial\",\n",
    "        rc={\"axes.titlesize\": 16,\n",
    "            \"axes.labelsize\": 14,\n",
    "            \"xtick.labelsize\": 12,\n",
    "            \"ytick.labelsize\": 12,\n",
    "            \"axes.spines.right\": False,\n",
    "            \"axes.spines.top\": False\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9072d7-f80a-4654-b6d8-ef4d48ef58bb",
   "metadata": {},
   "source": [
    "### Load in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad3ca1c-029f-4d0b-b094-d5d2ac5311e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load in dataset\n",
    "\n",
    "    Should be in long format. Following columns have to be present:\n",
    "        'subj': indicating subject number\n",
    "        'resp': indicating the responses or emissions (IMPORTANT: should be 0 and 1, and rows with missing values should be removed)\n",
    "         Additional input variables you want to include as predictor in the model (e.g. stimulus, previous response,...)\n",
    "         Binary variables should be transformed to -1 and 1, continuous variables are prefeably also scaled between -1 and 1.\n",
    "         Interactions should be in the dataset itself (i.e., one column where two variables are multiplied)\n",
    "        \n",
    "    num_inputs:\n",
    "        Indicate number of input variables that will be used in the model.\n",
    "        Basically, how many predictors do you want to use to predict 'response'.\n",
    "        For example: stimulus, previous resp, previous stimulus -> num_input = 3\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Load your empirical dataset (long format)\n",
    "per = pd.read_csv(\"../../Data/PerceptualTaskData.csv\")\n",
    "sym = pd.read_csv(\"../../Data/SymptomData.csv\")\n",
    "\n",
    "# Rename columns to the names expected throughout this notebook\n",
    "data = per.rename(columns={\n",
    "    \"IDcode\": \"subj\",\n",
    "    \"Response\": \"resp\",\n",
    "    \"Stimulus\": \"evidence\",\n",
    "    \"Trial\": \"trial\"\n",
    "}).copy()\n",
    "\n",
    "# Safety: drop evidence==0 (should not matter if only -1/+1)\n",
    "data = data[data[\"evidence\"] != 0].copy()\n",
    "\n",
    "# Ensure correct dtype for emissions\n",
    "data[\"resp\"] = data[\"resp\"].astype(int)\n",
    "\n",
    "# IMPORTANT: number of predictors we include in the model\n",
    "num_inputs = 1  # only stimulus evidence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc828f9e",
   "metadata": {},
   "source": [
    "### Put dataset in correct data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3374acdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: (1098, 144, 1)\n",
      "emissions: (1098, 144)\n",
      "masks: (1098, 144)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Create 'inputs', 'emissions', and 'masks' for hMFC.\n",
    "\n",
    "- inputs:   (num_subjects, num_trials_max, num_inputs)\n",
    "- emissions:(num_subjects, num_trials_max)\n",
    "- masks:    (num_subjects, num_trials_max)\n",
    "\n",
    "Mask is 1 for real trials and 0 for padded trials.\n",
    "\"\"\"\n",
    "\n",
    "# Stable subject ordering (critical to map posterior a_i back to IDcode later)\n",
    "subj_ids = np.sort(data.subj.unique())\n",
    "\n",
    "num_trials_per_subject = jnp.array(data.groupby(\"subj\").size().reindex(subj_ids).values)\n",
    "max_num_trials = int(num_trials_per_subject.max())\n",
    "num_trials = max_num_trials  # used later for posterior_samples_states\n",
    "\n",
    "inputs, emissions, masks = [], [], []\n",
    "\n",
    "for sid in subj_ids:\n",
    "    df = data[data.subj == sid].sort_values(\"trial\")\n",
    "\n",
    "    # Predictor: stimulus evidence (already -1/+1 in your file)\n",
    "    evidence = jnp.array(df.evidence.values, dtype=jnp.float32)   # (T,)\n",
    "    resp = jnp.array(df.resp.values, dtype=jnp.int32)             # (T,)\n",
    "\n",
    "    # inputs_subj shape (T, num_inputs) where num_inputs=1\n",
    "    inputs_subj = jnp.stack([evidence], axis=1)                   # (T,1)\n",
    "\n",
    "    # Mean-center inputs per subject (required in this implementation)\n",
    "    inputs_subj = inputs_subj - jnp.mean(inputs_subj, axis=0)\n",
    "\n",
    "    emissions_subj = resp\n",
    "    masks_subj = jnp.ones_like(emissions_subj)\n",
    "\n",
    "    # Pad up to max_num_trials\n",
    "    T = df.shape[0]\n",
    "    if T < max_num_trials:\n",
    "        pad = max_num_trials - T\n",
    "        zero_input = jnp.zeros((pad, num_inputs), dtype=jnp.float32)\n",
    "        zero_emissions = jnp.zeros((pad,), dtype=jnp.int32)\n",
    "\n",
    "        inputs_subj = jnp.vstack([inputs_subj, zero_input])\n",
    "        emissions_subj = jnp.concatenate([emissions_subj, zero_emissions])\n",
    "        masks_subj = jnp.concatenate([masks_subj, zero_emissions])\n",
    "\n",
    "    inputs.append(inputs_subj)\n",
    "    emissions.append(emissions_subj)\n",
    "    masks.append(masks_subj)\n",
    "\n",
    "inputs = jnp.array(inputs)\n",
    "emissions = jnp.array(emissions)\n",
    "masks = jnp.array(masks)\n",
    "\n",
    "num_subjects = inputs.shape[0]\n",
    "\n",
    "print(\"inputs:\", inputs.shape)\n",
    "print(\"emissions:\", emissions.shape)\n",
    "print(\"masks:\", masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f0d6c-951f-442b-8459-533129dc7bb0",
   "metadata": {},
   "source": [
    "### Initialize some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c09d9-199f-4559-811e-d16b32e65bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    num_chains: number of chains to run in parallel for the estimation procedure\n",
    "    num_iters: number of iterations for the estimation procedure\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "num_chains = 4\n",
    "num_iters = 2000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79325d-4426-46a3-9f34-d58131b45202",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c4ae69-9037-4453-9fcb-53cd302ff255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_and_fit_model(key):\n",
    "    \n",
    "    \"\"\"\n",
    "    Initialize model\n",
    "    \"\"\"\n",
    "    key = jr.PRNGKey(key) if isinstance(key, int) else key\n",
    "    k1, k2, k3, k4, k5, k6, k7 = jr.split(key, 7)\n",
    "     \n",
    "    init_mu_w = tfd.Uniform(-1.0, 1.0).sample(seed=k1, sample_shape=(num_inputs,))\n",
    "    init_sigma_w = tfd.Uniform(0.1, 1.0).sample(seed=k2, sample_shape=(num_inputs,))\n",
    "    init_mu_a = tfd.Uniform(0.5, 0.995).sample(seed=k3)\n",
    "    init_sigma_a = tfd.Uniform(0.1, 0.2).sample(seed=k4) # there is an upper limit for sigma_a, so don't exceed 0.2, otherwise parameter is not updated!\n",
    "    init_mu_sigmasq = tfd.Uniform(0.05, 0.2).sample(seed=k5)\n",
    "    init_beta_sigmasq = tfd.Uniform(0.05, 0.5).sample(seed=k6)\n",
    "    init_sigma_mu_x = tfd.Uniform(0.1, 0.5).sample(seed=k7)\n",
    "    \n",
    "    model = HierarchicalBernoulliLDS(num_inputs, init_mu_a, init_sigma_a, init_mu_w, init_sigma_w, init_mu_sigmasq, init_beta_sigmasq, init_sigma_mu_x)\n",
    "    params, states, _ = model.sample(key, inputs) # sample initial per-subject parameters and states (criterion trajectory)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Fit model\n",
    "    \"\"\"\n",
    "    lps = jnp.zeros((num_iters,)) # log probability\n",
    "    \n",
    "    posterior_samples_mu_a = jnp.zeros((num_iters,))\n",
    "    posterior_samples_sigma_a = jnp.zeros((num_iters,))\n",
    "    posterior_samples_mu_w = jnp.zeros((num_iters, num_inputs))\n",
    "    posterior_samples_sigma_w = jnp.zeros((num_iters, num_inputs))\n",
    "    posterior_samples_mu_sigmasq = jnp.zeros((num_iters,))\n",
    "    posterior_samples_beta_sigmasq = jnp.zeros((num_iters,))\n",
    "    posterior_samples_sigma_mu_x = jnp.zeros((num_iters,))\n",
    "    \n",
    "    posterior_samples_a = jnp.zeros((num_iters, num_subjects))\n",
    "    posterior_samples_sigmasq = jnp.zeros((num_iters, num_subjects))\n",
    "    posterior_samples_w = jnp.zeros((num_iters, num_subjects, num_inputs))\n",
    "    posterior_samples_mu_x = jnp.zeros((num_iters, num_subjects))\n",
    "\n",
    "    posterior_samples_states = jnp.zeros((num_iters, num_subjects, num_trials))\n",
    "    \n",
    "    for itr in progress_bar(range(num_iters)):\n",
    "\n",
    "        this_key, key = jr.split(key)\n",
    "        lp, states, params, model = gibbs_step(this_key, emissions, masks, states, inputs, params, model)\n",
    "        \n",
    "        lps = lps.at[itr].set(lp)\n",
    "\n",
    "        posterior_samples_mu_a = posterior_samples_mu_a.at[itr].set(sigmoid(model.logit_mu_a))\n",
    "        posterior_samples_sigma_a = posterior_samples_sigma_a.at[itr].set(jnp.exp(model.log_sigma_a))\n",
    "        posterior_samples_mu_w = posterior_samples_mu_w.at[itr].set(model.mu_w)\n",
    "        posterior_samples_sigma_w = posterior_samples_sigma_w.at[itr].set(jnp.exp(model.log_sigma_w))\n",
    "        posterior_samples_mu_sigmasq = posterior_samples_mu_sigmasq.at[itr].set(jnp.exp(model.log_mu_sigmasq))\n",
    "        posterior_samples_beta_sigmasq = posterior_samples_beta_sigmasq.at[itr].set(jnp.exp(model.log_beta_sigmasq))\n",
    "        posterior_samples_sigma_mu_x = posterior_samples_sigma_mu_x.at[itr].set(jnp.exp(model.log_sigma_mu_x))\n",
    "\n",
    "\n",
    "        posterior_samples_a = posterior_samples_a.at[itr].set(params['a'])\n",
    "        posterior_samples_sigmasq = posterior_samples_sigmasq.at[itr].set(params['sigmasq'])\n",
    "        posterior_samples_w = posterior_samples_w.at[itr].set(params['w'])\n",
    "        posterior_samples_mu_x = posterior_samples_mu_x.at[itr].set(params['mu_x'])\n",
    "        \n",
    "        posterior_samples_states = posterior_samples_states.at[itr].set(states)\n",
    "    \n",
    "\n",
    "    return posterior_samples_mu_a, posterior_samples_sigma_a, posterior_samples_mu_w, posterior_samples_sigma_w, posterior_samples_mu_sigmasq, posterior_samples_beta_sigmasq, posterior_samples_sigma_mu_x, posterior_samples_a, posterior_samples_sigmasq, posterior_samples_w, posterior_samples_mu_x, posterior_samples_states, lps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4d83d1-583c-4a79-b5e3-8e17ffce0f51",
   "metadata": {},
   "source": [
    "### Run multiple chains in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "445bf931-a67e-455e-9fe6-f635240360bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      14.00% [7/50 06:37&lt;40:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m keys \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39msplit(jr\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), num_chains)\n\u001b[0;32m----> 3\u001b[0m posterior_samples_mu_a, posterior_samples_sigma_a, posterior_samples_mu_w, posterior_samples_sigma_w, posterior_samples_mu_sigmasq, posterior_samples_beta_sigmasq, posterior_samples_sigma_mu_x, posterior_samples_a, posterior_samples_sigmasq, posterior_samples_w, posterior_samples_mu_x, posterior_samples_states, lps \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitialize_and_fit_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/api.py:1129\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1127\u001b[0m   axis_data \u001b[38;5;241m=\u001b[39m batching\u001b[38;5;241m.\u001b[39mAxisData(axis_name, axis_size_, spmd_axis_name,\n\u001b[1;32m   1128\u001b[0m                                 explicit_mesh_axis)\n\u001b[0;32m-> 1129\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m batching\u001b[38;5;241m.\u001b[39mSpecMatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m   out_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap out_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_tree(), out_axes)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/linear_util.py:211\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:618\u001b[0m, in \u001b[0;36m_batch_outer\u001b[0;34m(f, axis_data, in_dims, *in_vals)\u001b[0m\n\u001b[1;32m    616\u001b[0m tag \u001b[38;5;241m=\u001b[39m TraceTag()\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m source_info_util\u001b[38;5;241m.\u001b[39mtransform_name_stack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 618\u001b[0m   outs, trace \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mensure_no_leaks(trace): \u001b[38;5;28;01mdel\u001b[39;00m trace\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:634\u001b[0m, in \u001b[0;36m_batch_inner\u001b[0;34m(f, axis_data, out_dim_dests, tag, in_dims, *in_vals)\u001b[0m\n\u001b[1;32m    630\u001b[0m   in_tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(partial(to_elt, trace, idx), in_vals, in_dims)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (core\u001b[38;5;241m.\u001b[39mset_current_trace(trace),\n\u001b[1;32m    632\u001b[0m       core\u001b[38;5;241m.\u001b[39mextend_axis_env_nd([(axis_data\u001b[38;5;241m.\u001b[39mname, axis_data\u001b[38;5;241m.\u001b[39msize)]),\n\u001b[1;32m    633\u001b[0m       core\u001b[38;5;241m.\u001b[39madd_spmd_axis_names(axis_data\u001b[38;5;241m.\u001b[39mspmd_name)):\n\u001b[0;32m--> 634\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m   out_dim_dests \u001b[38;5;241m=\u001b[39m out_dim_dests() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(out_dim_dests) \u001b[38;5;28;01melse\u001b[39;00m out_dim_dests\n\u001b[1;32m    636\u001b[0m   out_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(partial(from_elt, trace, axis_data\u001b[38;5;241m.\u001b[39msize, axis_data\u001b[38;5;241m.\u001b[39mexplicit_mesh_axis),\n\u001b[1;32m    637\u001b[0m                  \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(outs)), outs, out_dim_dests)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:342\u001b[0m, in \u001b[0;36mflatten_fun_for_vmap\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun_for_vmap\u001b[39m(f: Callable,\n\u001b[1;32m    340\u001b[0m                          store: lu\u001b[38;5;241m.\u001b[39mStore, in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m    341\u001b[0m   py_args, py_kwargs \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m--> 342\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans, is_leaf\u001b[38;5;241m=\u001b[39mis_vmappable)\n\u001b[1;32m    344\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/linear_util.py:396\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 396\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_clean_keystr_arg_names(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans))\n\u001b[1;32m    398\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 53\u001b[0m, in \u001b[0;36minitialize_and_fit_model\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     51\u001b[0m posterior_samples_sigma_w \u001b[38;5;241m=\u001b[39m posterior_samples_sigma_w\u001b[38;5;241m.\u001b[39mat[itr]\u001b[38;5;241m.\u001b[39mset(jnp\u001b[38;5;241m.\u001b[39mexp(model\u001b[38;5;241m.\u001b[39mlog_sigma_w))\n\u001b[1;32m     52\u001b[0m posterior_samples_mu_sigmasq \u001b[38;5;241m=\u001b[39m posterior_samples_mu_sigmasq\u001b[38;5;241m.\u001b[39mat[itr]\u001b[38;5;241m.\u001b[39mset(jnp\u001b[38;5;241m.\u001b[39mexp(model\u001b[38;5;241m.\u001b[39mlog_mu_sigmasq))\n\u001b[0;32m---> 53\u001b[0m posterior_samples_beta_sigmasq \u001b[38;5;241m=\u001b[39m \u001b[43mposterior_samples_beta_sigmasq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitr\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_beta_sigmasq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m posterior_samples_sigma_mu_x \u001b[38;5;241m=\u001b[39m posterior_samples_sigma_mu_x\u001b[38;5;241m.\u001b[39mat[itr]\u001b[38;5;241m.\u001b[39mset(jnp\u001b[38;5;241m.\u001b[39mexp(model\u001b[38;5;241m.\u001b[39mlog_sigma_mu_x))\n\u001b[1;32m     57\u001b[0m posterior_samples_a \u001b[38;5;241m=\u001b[39m posterior_samples_a\u001b[38;5;241m.\u001b[39mat[itr]\u001b[38;5;241m.\u001b[39mset(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:814\u001b[0m, in \u001b[0;36m_IndexUpdateRef.set\u001b[0;34m(self, values, indices_are_sorted, unique_indices, mode)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_s\u001b[38;5;241m.\u001b[39mmesh\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mor\u001b[39;00m out_s\u001b[38;5;241m.\u001b[39mmesh\u001b[38;5;241m.\u001b[39m_are_all_axes_auto_or_manual:\n\u001b[1;32m    813\u001b[0m   out_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scatter_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m                               \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mout_sharding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_s\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/ops/scatter.py:92\u001b[0m, in \u001b[0;36m_scatter_update\u001b[0;34m(x, idx, y, scatter_op, indices_are_sorted, unique_indices, mode, normalize_indices, out_sharding)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_sharding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m auto_axes(internal_scatter, out_sharding\u001b[38;5;241m=\u001b[39mout_sharding\n\u001b[1;32m     91\u001b[0m                    )(x, y, dynamic_idx)\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minternal_scatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/ops/scatter.py:129\u001b[0m, in \u001b[0;36m_scatter_impl\u001b[0;34m(x, y, dynamic_idx, scatter_op, treedef, static_idx, indices_are_sorted, unique_indices, mode, normalize_indices)\u001b[0m\n\u001b[1;32m    127\u001b[0m y \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mbroadcast_to(y, \u001b[38;5;28mtuple\u001b[39m(indexer\u001b[38;5;241m.\u001b[39mslice_shape))\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Collapse any `None`/`np.newaxis` dimensions.\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer\u001b[38;5;241m.\u001b[39mreversed_y_dims:\n\u001b[1;32m    131\u001b[0m   y \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mrev(y, indexer\u001b[38;5;241m.\u001b[39mreversed_y_dims)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2340\u001b[0m, in \u001b[0;36msqueeze\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m   2284\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Remove one or more length-1 axes from array\u001b[39;00m\n\u001b[1;32m   2285\u001b[0m \n\u001b[1;32m   2286\u001b[0m \u001b[38;5;124;03mJAX implementation of :func:`numpy.sqeeze`, implemented via :func:`jax.lax.squeeze`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;124;03m  Array([0, 1, 2], dtype=int32)\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m arr \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mensure_arraylike(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqueeze\u001b[39m\u001b[38;5;124m\"\u001b[39m, a)\n\u001b[0;32m-> 2340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_squeeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ensure_index_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/pjit.py:292\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mno_tracing\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    288\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info\u001b[38;5;241m.\u001b[39mfun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`jit`, but \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_tracing\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    291\u001b[0m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, box_data,\n\u001b[0;32m--> 292\u001b[0m  executable, pgle_profiler) \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m    295\u001b[0m     executable, out_tree, args_flat, out_flat, attrs_tracked, box_data,\n\u001b[1;32m    296\u001b[0m     jaxpr\u001b[38;5;241m.\u001b[39meffects, jaxpr\u001b[38;5;241m.\u001b[39mconsts, jit_info\u001b[38;5;241m.\u001b[39mabstracted_axes, pgle_profiler)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/pjit.py:155\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m   out_flat, compiled, profiler \u001b[38;5;241m=\u001b[39m _pjit_call_impl_python(\u001b[38;5;241m*\u001b[39margs_flat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m   compiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    157\u001b[0m   profiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/core.py:536\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    535\u001b[0m   args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[0;32m--> 536\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/core.py:552\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    550\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/core.py:562\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m set_current_trace(trace):\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_lojax(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:498\u001b[0m, in \u001b[0;36mBatchTrace.process_primitive\u001b[0;34m(self, p, tracers, params)\u001b[0m\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_trace):\n\u001b[0;32m--> 498\u001b[0m       val_out, dim_out \u001b[38;5;241m=\u001b[39m \u001b[43mfancy_primitive_batchers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args_not_mapped:\n\u001b[1;32m    501\u001b[0m   \u001b[38;5;66;03m# no-op shortcut\u001b[39;00m\n\u001b[1;32m    502\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m p\u001b[38;5;241m.\u001b[39mbind_with_trace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_trace, vals_in, params)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/pjit.py:2170\u001b[0m, in \u001b[0;36m_pjit_batcher\u001b[0;34m(axis_data, vals_in, dims_in, jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, donated_invars, ctx_mesh, name, keep_unused, inline, compiler_options_kvs)\u001b[0m\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mall\u001b[39m(l \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m in_layouts) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   2166\u001b[0m         \u001b[38;5;28mall\u001b[39m(l \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m out_layouts)):\n\u001b[1;32m   2167\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   2168\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcrete layouts are not supported for vmap(jit).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2170\u001b[0m vals_out \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2171\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvals_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_jaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m  \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m  \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m  \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m  \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2177\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[43m  \u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m  \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2180\u001b[0m \u001b[43m  \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2181\u001b[0m \u001b[43m  \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2184\u001b[0m resolved_axes_out \u001b[38;5;241m=\u001b[39m batching\u001b[38;5;241m.\u001b[39mresolve_ragged_axes_against_inputs_outputs(\n\u001b[1;32m   2185\u001b[0m     vals_in, vals_out, axes_out)\n\u001b[1;32m   2186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vals_out, resolved_axes_out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/core.py:536\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    535\u001b[0m   args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[0;32m--> 536\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/core.py:552\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    550\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/core.py:562\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m set_current_trace(trace):\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_lojax(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/hmfc/lib/python3.10/site-packages/jax/_src/core.py:1066\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, args, params)\u001b[0m\n\u001b[1;32m   1064\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(full_lower, args)\n\u001b[1;32m   1065\u001b[0m check_eval_args(args)\n\u001b[0;32m-> 1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keys = jr.split(jr.PRNGKey(0), num_chains)\n",
    "\n",
    "posterior_samples_mu_a, posterior_samples_sigma_a, posterior_samples_mu_w, posterior_samples_sigma_w, posterior_samples_mu_sigmasq, posterior_samples_beta_sigmasq, posterior_samples_sigma_mu_x, posterior_samples_a, posterior_samples_sigmasq, posterior_samples_w, posterior_samples_mu_x, posterior_samples_states, lps = vmap(initialize_and_fit_model)(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c7747-1876-4302-8e99-81ff751a0c66",
   "metadata": {},
   "source": [
    "### Save variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e041d96-d168-4e57-85a6-8e541773546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'YOUR_PATH_AND_FILENAME_HERE.dil'\n",
    "\n",
    "list_of_variable_names = (\"lps\", \n",
    "  \"posterior_samples_mu_a\", \"posterior_samples_sigma_a\",\n",
    "  \"posterior_samples_mu_sigmasq\", \"posterior_samples_beta_sigmasq\",\n",
    "  \"posterior_samples_mu_w\", \"posterior_samples_sigma_w\",\n",
    "  \"posterior_samples_sigma_mu_x\", \"posterior_samples_mu_x\",\n",
    "  \"posterior_samples_a\",\"posterior_samples_sigmasq\",\n",
    "  \"posterior_samples_w\", \"posterior_samples_states\",\n",
    "  \"num_trials\", \"num_inputs\",\"num_trials_per_subject\",\"num_subjects\",\"num_iters\", \"inputs\", \"emissions\", \"masks\")\n",
    "\n",
    "\n",
    "with open(file_name, 'wb') as file:\n",
    "    dill.dump(list_of_variable_names, file)  # Store all the names first\n",
    "    \n",
    "    for variable_name in list_of_variable_names:\n",
    "        dill.dump(eval(variable_name), file) # Store the objects themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed7901",
   "metadata": {},
   "source": [
    "### Load in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98461c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'YOUR_PATH_AND_FILENAME_HERE.dil'\n",
    "\n",
    "g = globals()\n",
    "with open(file_name,'rb') as file:\n",
    "    list_of_variable_names = dill.load(file)  # Get the names of stored objects\n",
    "    for variable_name in list_of_variable_names:\n",
    "        g[variable_name] = dill.load(file)    # Get the objects themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580787ea",
   "metadata": {},
   "source": [
    "### Log joint probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0930a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Check log joint probability to assess convergence and determine number of burn-in iterations\n",
    "\n",
    "Ideally, the log joint probability should stabilize and fluctuate around a certain value for a couple of hundereds iterations.\n",
    "If it is still clearly increasing then rerun the model with more iterations. The first iterations where the log joint probability\n",
    "is still increasing should be considered burn-in.\n",
    "\"\"\"\n",
    "\n",
    "for i in range(lps.shape[0]):\n",
    "    plt.plot(lps[i]/emissions.size, label=f'Chain {i + 1}') \n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log joint probability\")\n",
    "plt.title(\"Normalized Log Joint Probability Chains\") \n",
    "plt.legend() \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae48e6c3-cee1-4c88-878f-a09b301513d2",
   "metadata": {},
   "source": [
    "### Per-subject parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c7f90-761a-4c60-b7bf-27a5ffe73af8",
   "metadata": {},
   "source": [
    "#### Slopes input variables $w_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd090768-326b-4382-979c-047a5527740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_w = posterior_samples_w[:,burn_in:,:,:] # (num_chains, num_iterations, num_subjects, num_inputs)\n",
    "post_w = post_w.reshape(-1, num_subjects, num_inputs) # collapse samples over the chains\n",
    "\n",
    "fig, axs = plt.subplots(1, num_inputs, sharey=True, figsize=(12, 6))\n",
    "for d, ax in enumerate(axs):\n",
    "    ax.hist(jnp.mean(post_w[:,:,d], axis=0), bins=num_subjects, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel(r\"$w_{:d}$\".format(d))\n",
    "    if d == 0: ax.set_ylabel(\"Count\")\n",
    "plt.suptitle(r\"Posterior means of $w_i$\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3749e7",
   "metadata": {},
   "source": [
    "#### Autoregressive coefficient $a_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a411e25-d664-47ee-b47b-01cabae6721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_a = posterior_samples_a[:,burn_in:,:] # (num_chains, num_iterations, num_subjects)\n",
    "post_a = post_a.reshape(-1, num_subjects) # collapse samples over the chains\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(jnp.mean(post_a, axis=0), bins=num_subjects, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(r\"$a$\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(r\"Posterior means of $a_i$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e85fe",
   "metadata": {},
   "source": [
    "#### Error variance $\\sigma^2_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sigmasq = posterior_samples_sigmasq[:,burn_in:,:] # (num_chains, num_iterations, num_subjects)\n",
    "post_sigmasq = post_sigmasq.reshape(-1, num_subjects) # collapse samples over the chains\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(jnp.mean(post_sigmasq, axis=0), bins=num_subjects, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(r\"$\\sigma^2_i$\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(r\"Posterior means of $\\sigma^2_i$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc07dc2",
   "metadata": {},
   "source": [
    "#### Criterion mean $\\mu_{x,i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mu_x = posterior_samples_mu_x[:,burn_in:,:] # (num_chains, num_iterations, num_subjects)\n",
    "post_mu_x = post_mu_x.reshape(-1, num_subjects) # collapse samples over the chains\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(jnp.mean(post_mu_x, axis=0), bins=num_subjects, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(r\"$\\mu_{x,i}$\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(r\"Posterior means of $\\mu_{x,i}$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ccae4",
   "metadata": {},
   "source": [
    "### Criterion fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab28636",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_subject = 0\n",
    "\n",
    "\n",
    "post_states = posterior_samples_states[:,burn_in:,:,:] # (num_chains, num_iterations, num_subjects, num_trials)\n",
    "post_states = post_states.reshape(-1, num_subjects, num_trials) # collapse samples over the chains\n",
    "\n",
    "posterior_samples_states_mean = jnp.mean(post_states[:,:,:], axis=0) \n",
    "posterior_samples_states_std = jnp.std(post_states[:,:,:], axis=0)\n",
    "\n",
    "post_a = posterior_samples_a[:,burn_in:,:] # (num_chains, num_iterations, num_subjects)\n",
    "post_a = post_a.reshape(-1, num_subjects) # collapse samples over the chains\n",
    "\n",
    "post_sigmasq = posterior_samples_sigmasq[:,burn_in:,:] # (num_chains, num_iterations, num_subjects)\n",
    "post_sigmasq = post_sigmasq.reshape(-1, num_subjects) # collapse samples over the chains\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(posterior_samples_states_mean[example_subject], label=\"Inferred states\")\n",
    "plt.fill_between(jnp.arange(num_trials), #95% CI\n",
    "            posterior_samples_states_mean[example_subject] - 2 * posterior_samples_states_std[example_subject],\n",
    "            posterior_samples_states_mean[example_subject] + 2 * posterior_samples_states_std[example_subject], color='r', alpha=0.25)\n",
    "plt.xlabel(\"Trial\")\n",
    "plt.ylabel(\"Criterion $x_t$\")\n",
    "plt.annotate(r'$a$ = {:.3f}'.format(jnp.mean(post_a, axis=0)[example_subject]), xy=(0.05, 0.95), xycoords='axes fraction')\n",
    "plt.annotate(r'$\\sigma^2$ = {:.3f}'.format(jnp.mean(post_sigmasq, axis=0)[example_subject]), xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "plt.title(r\"Subject {:d}\".format(example_subject))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create pdf of all subjects\n",
    "\"\"\"\n",
    "\n",
    "post_states = posterior_samples_states[:,burn_in:,:,:] # (num_chains, num_iterations, num_subjects, num_trials)\n",
    "post_states = post_states.reshape(-1, num_subjects, num_trials) # collapse samples over the chains\n",
    "\n",
    "posterior_samples_states_mean = jnp.mean(post_states[:,:,:], axis=0) \n",
    "posterior_samples_states_std = jnp.std(post_states[:,:,:], axis=0)\n",
    "\n",
    "post_a = posterior_samples_a[:,burn_in:,:] # (num_chains, num_iterations, num_subjects)\n",
    "post_a = post_a.reshape(-1, num_subjects) # collapse samples over the chains\n",
    "\n",
    "post_sigmasq = posterior_samples_sigmasq[:,burn_in:,:] # (num_chains, num_iterations, num_subjects)\n",
    "post_sigmasq = post_sigmasq.reshape(-1, num_subjects) # collapse samples over the chains\n",
    "\n",
    "with PdfPages('estimated_criterion_trajectory.pdf') as pdf:\n",
    "  for subject in range(num_subjects):\n",
    "      \n",
    "      plt.figure(figsize=(8, 6))\n",
    "      plt.plot(posterior_samples_states_mean[subject], label=\"Inferred states\")\n",
    "      plt.fill_between(jnp.arange(num_trials), #95% CI\n",
    "                  posterior_samples_states_mean[subject] - 2 * posterior_samples_states_std[subject],\n",
    "                  posterior_samples_states_mean[subject] + 2 * posterior_samples_states_std[subject], color='r', alpha=0.25)\n",
    "      plt.xlabel(\"Trial\")\n",
    "      plt.ylabel(\"Criterion $x_t$\")\n",
    "      plt.annotate(r'$a$ = {:.3f}'.format(jnp.mean(post_a, axis=0)[subject]), xy=(0.05, 0.95), xycoords='axes fraction')\n",
    "      plt.annotate(r'$\\sigma^2$ = {:.3f}'.format(jnp.mean(post_sigmasq, axis=0)[subject]), xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "      plt.title(r\"Subject {:d}\".format(subject))\n",
    "      plt.tight_layout()\n",
    "\n",
    "      pdf.savefig(dpi=600)\n",
    "      plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Save the estimated criterion fluctuations by adding them to original dataframe\n",
    "\"\"\"\n",
    "\n",
    "# collapse over subjects while taking into account potentially different numbers of trials per subject\n",
    "data['criterion_fluctuations'] = jnp.concatenate([posterior_samples_states_mean[i, :num_trials_per_subject[i]] for i in range(len(num_trials_per_subject))]) \n",
    "\n",
    "data.to_csv('YOUR_DF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15257da7",
   "metadata": {},
   "source": [
    "### Group-level parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a169b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rhat should be close to 1 for all parameters\n",
    "# A value of 1.1 or less is generally considered acceptable\n",
    "\n",
    "def calculate_r_hat(samples):\n",
    "    # Assuming samples is a 2D array of shape (num_chains, num_samples)\n",
    "    num_chains, num_samples = samples.shape\n",
    "    \n",
    "    # Calculate the within-chain variance\n",
    "    W = np.mean(np.var(samples, axis=1, ddof=1))\n",
    "    # Calculate the between-chain variance\n",
    "    chain_means = np.mean(samples, axis=1)\n",
    "    B = num_samples * np.var(chain_means, ddof=1)\n",
    "    # Estimate the marginal posterior variance\n",
    "    var_plus = ((num_samples - 1) / num_samples) * W + (1 / num_samples) * B\n",
    "    # Calculate R-hat\n",
    "    r_hat = np.sqrt(var_plus / W)\n",
    "    return r_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a31e19",
   "metadata": {},
   "source": [
    "#### Posterior distribution of $\\mu_w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f95f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mu_w = posterior_samples_mu_w[:,burn_in:,:] # (num_chains, num_iterations, num_inputs)\n",
    "post_mu_w = post_mu_w.reshape(-1, num_inputs) # collapse samples over the chains\n",
    "\n",
    "fig, axs = plt.subplots(1, num_inputs, sharey=True, figsize=(12, 6))\n",
    "for d, ax in enumerate(axs):\n",
    "    ax.hist(post_mu_w[:,d], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel(r\"$\\mu_{{w_{:d}}}$\".format(d))\n",
    "    if d == 0: ax.set_ylabel(\"Count\")\n",
    "plt.suptitle(r\"Posterior means of $\\mu_w$\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c299fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "fig.delaxes(axes[-1])  # Removes the last (6th) axis (if num_inputs is 5)\n",
    "\n",
    "for j in range(posterior_samples_mu_w.shape[2]):\n",
    "    ax = axes[j]\n",
    "    ax.axvline(x = burn_in, color = 'black', linestyle='dashed', label = 'Burn-in')\n",
    "    \n",
    "    for i in range(posterior_samples_mu_w.shape[0]):  # looping over chains\n",
    "        ax.plot(posterior_samples_mu_w[i, :, j], label=f\"Chains {i+1}\")\n",
    "    \n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(f\"$\\mu_{{w_{j}}}$\")\n",
    "    ax.annotate(r'Rhat (burn-in removed) = {:.4f}'.format(calculate_r_hat(posterior_samples_mu_w[:, burn_in:, j])), xy=(0.02, 1.03), size= 12, xycoords='axes fraction')\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.1), fontsize=12, ncol=6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f21166",
   "metadata": {},
   "source": [
    "#### Hypothesis testing $\\mu_w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3525cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "The posteriors distributions of the group-level mu_w can be used to assess the significance\n",
    "of a predictor variable. To do so, we use zero as cutoff and check which side (left or right)\n",
    "has the smallest tail. Next, we calculate the area of this smallest tail and multiply by two \n",
    "(to perform two-sided hypothesis testing). The resulting value is the p-value!\n",
    "\n",
    "Note that performing a one sample t-test against zero based on the per-subject w's is not correct.\n",
    "Due to the hierarchical nature of hMFC, these per-subject estimates are not independent.\n",
    "In contrast, the t-test assumes these values to be independent.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "variable_index = 0 # which of the w's you want to test\n",
    "\n",
    "if jnp.median(post_mu_w[:,variable_index]) < 0: # right tail is the smallest\n",
    "    p_value = (sum(post_mu_w[:,variable_index] > 0)/len(post_mu_w[:,variable_index]))*2\n",
    "    \n",
    "else: # left tail is smallest\n",
    "    p_value = (sum(post_mu_w[:,variable_index] < 0)/len(post_mu_w[:,variable_index]))*2\n",
    "\n",
    "if p_value < .05:\n",
    "    outcome = \"significantly\"\n",
    "else: \n",
    "    outcome = \"not significantly\"\n",
    "    \n",
    "print(r\"The posterior of w\"+str(variable_index)+\" with mean \"+str(jnp.round(jnp.mean(post_mu_w[:,variable_index]),decimals=4))+\" is \"+str(outcome)+\" different from 0 (p=\"+str(p_value)+\")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4cfdf4",
   "metadata": {},
   "source": [
    "#### Posterior distribution of $\\sigma_w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e83b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sigma_w = posterior_samples_sigma_w[:,burn_in:,:] # (num_chains, num_iterations, num_inputs)\n",
    "post_sigma_w = post_sigma_w.reshape(-1, num_inputs) # collapse samples over the chains\n",
    "\n",
    "fig, axs = plt.subplots(1, num_inputs, sharey=True, figsize=(12, 6))\n",
    "for d, ax in enumerate(axs):\n",
    "    ax.hist(post_sigma_w[:,d], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    ax.set_xlabel(r\"$\\sigma_{{w_{:d}}}$\".format(d))\n",
    "    if d == 0: ax.set_ylabel(\"Count\")\n",
    "plt.suptitle(r\"Posterior means of $\\sigma_w$\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "fig.delaxes(axes[-1])  # Removes the last (6th) axis (if num_inputs is 5)\n",
    "\n",
    "for j in range(posterior_samples_sigma_w.shape[2]):\n",
    "    ax = axes[j]\n",
    "    ax.axvline(x = burn_in, color = 'black', linestyle='dashed', label = 'Burn-in')\n",
    "    \n",
    "    for i in range(posterior_samples_sigma_w.shape[0]):  # looping over chains\n",
    "        ax.plot(posterior_samples_sigma_w[i, :, j], label=f\"Chains {i+1}\")\n",
    "    \n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(f\"$\\sigma_{{w_{j}}}$\")\n",
    "    ax.annotate(r'Rhat (burn-in removed) = {:.4f}'.format(calculate_r_hat(posterior_samples_sigma_w[:, burn_in:, j])), xy=(0.02, 1.03), size= 12, xycoords='axes fraction')\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.1), fontsize=12, ncol=6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0febfe",
   "metadata": {},
   "source": [
    "#### Posterior distribution of $\\mu_a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mu_a = posterior_samples_mu_a[:,burn_in:] # (num_chains, num_iterations)\n",
    "post_mu_a = post_mu_a.reshape(-1) # collapse samples over the chains\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(post_mu_a, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(r\"$\\mu_a$\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(r\"Posterior $\\mu_a$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.axvline(x = burn_in, color = 'black', linestyle='dashed', label = 'Burn-in')\n",
    "for i in range(posterior_samples_mu_a.shape[0]): # looping over chains\n",
    "    plt.plot(posterior_samples_mu_a[i, :], label=f\"Chains {i+1}\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(r\"$\\mu_{{a}}$\")\n",
    "plt.annotate(r'Rhat (burn-in removed) = {:.4f}'.format(calculate_r_hat(posterior_samples_mu_a[:,burn_in:])), xy=(0.02, 1.03), size= 14, xycoords='axes fraction')\n",
    "plt.legend(fontsize=12) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af914b91",
   "metadata": {},
   "source": [
    "#### Posterior distribution of $\\sigma_a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sigma_a = posterior_samples_sigma_a[:,burn_in:] # (num_chains, num_iterations)\n",
    "post_sigma_a = post_sigma_a.reshape(-1) # collapse samples over the chains\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(post_sigma_a, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(r\"$\\sigma_a$\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(r\"Posterior $\\sigma_a$\")\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.axvline(x = burn_in, color = 'black', linestyle='dashed', label = 'Burn-in')\n",
    "for i in range(posterior_samples_sigma_a.shape[0]): # looping over chains\n",
    "    plt.plot(posterior_samples_sigma_a[i, :], label=f\"Chains {i+1}\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(r\"$\\sigma_{{a}}$\")\n",
    "plt.annotate(r'Rhat (burn-in removed) = {:.4f}'.format(calculate_r_hat(posterior_samples_sigma_a[:,burn_in:])), xy=(0.02, 1.03), size= 14, xycoords='axes fraction')\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0838ff0c",
   "metadata": {},
   "source": [
    "#### Posterior distribution of $\\mu_{\\sigma^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mu_sigmasq = posterior_samples_mu_sigmasq[:,burn_in:] # (num_chains, num_iterations)\n",
    "post_mu_sigmasq = post_mu_sigmasq.reshape(-1) # collapse samples over the chains\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(post_mu_sigmasq, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(r\"$\\mu_{\\sigma^2}$\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(r\"Posterior $\\mu_{\\sigma^2}$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.axvline(x = burn_in, color = 'black', linestyle='dashed', label = 'Burn-in')\n",
    "for i in range(posterior_samples_mu_sigmasq.shape[0]): # looping over chains\n",
    "    plt.plot(posterior_samples_mu_sigmasq[i, :], label=f\"Chains {i+1}\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(r\"$\\mu_{\\sigma^2}$\")\n",
    "plt.annotate(r'Rhat (burn-in removed) = {:.4f}'.format(calculate_r_hat(posterior_samples_mu_sigmasq[:,burn_in:])), xy=(0.02, 1.03), size= 14, xycoords='axes fraction')\n",
    "plt.legend(fontsize=12) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9eec1",
   "metadata": {},
   "source": [
    "#### Posterior distribution of $\\beta_{\\sigma2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a462521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_beta_sigmasq = posterior_samples_beta_sigmasq[:,burn_in:] # (num_chains, num_iterations)\n",
    "post_beta_sigmasq = post_beta_sigmasq.reshape(-1) # collapse samples over the chains\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(post_beta_sigmasq, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(r\"$\\beta_{\\sigma^2}$\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(r\"Posterior $\\beta_{\\sigma^2}$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d249c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.axvline(x = burn_in, color = 'black', linestyle='dashed', label = 'Burn-in')\n",
    "for i in range(posterior_samples_beta_sigmasq.shape[0]): # looping over chains\n",
    "    plt.plot(posterior_samples_beta_sigmasq[i, :], label=f\"Chains {i+1}\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(r\"$\\beta_{\\sigma^2}$\")\n",
    "plt.annotate(r'Rhat (burn-in removed) = {:.4f}'.format(calculate_r_hat(posterior_samples_beta_sigmasq[:,burn_in:])), xy=(0.02, 1.03), size= 14, xycoords='axes fraction')\n",
    "plt.legend(fontsize=12) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2af30a",
   "metadata": {},
   "source": [
    "#### Posterior distribution of $\\sigma_{\\mu_x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d85abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sigma_mu_x = posterior_samples_sigma_mu_x[:,burn_in:] # (num_chains, num_iterations)\n",
    "post_sigma_mu_x = post_sigma_mu_x.reshape(-1) # collapse samples over the chains\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(post_sigma_mu_x, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(r\"$\\sigma_{\\mu_x}$\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(r\"Posterior $\\sigma_{\\mu_x}$\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40bd70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.axvline(x = burn_in, color = 'black', linestyle='dashed', label = 'Burn-in')\n",
    "for i in range(posterior_samples_sigma_mu_x.shape[0]): # looping over chains\n",
    "    plt.plot(posterior_samples_sigma_mu_x[i, :], label=f\"Chains {i+1}\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(r\"$\\sigma_{\\mu_x}$\")\n",
    "plt.annotate(r'Rhat (burn-in removed) = {:.4f}'.format(calculate_r_hat(posterior_samples_sigma_mu_x[:,burn_in:])), xy=(0.02, 1.03), size= 14, xycoords='axes fraction')\n",
    "plt.legend(fontsize=12) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmfc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
